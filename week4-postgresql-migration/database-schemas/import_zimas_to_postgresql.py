#!/usr/bin/env python3
"""
Direct Import from ZIMAS SQLite to PostgreSQL
Imports 457K properties with all 97 ZIMAS fields directly to PostGIS database
"""

import sqlite3
import psycopg2
import json
import sys
import time
from typing import Dict, Any, List, Tuple, Optional
from decimal import Decimal

def connect_to_sqlite() -> sqlite3.Connection:
    """Connect to ZIMAS unified SQLite database"""
    db_path = './scraper/zimas_unified.db'
    try:
        conn = sqlite3.connect(db_path)
        print(f"‚úÖ Connected to SQLite: {db_path}")
        return conn
    except Exception as e:
        print(f"‚ùå Failed to connect to SQLite: {e}")
        sys.exit(1)

def connect_to_postgresql() -> psycopg2.extensions.connection:
    """Connect to PostgreSQL database"""
    try:
        conn = psycopg2.connect(
            host="localhost",
            database="dealgenie_production",
            user="dealgenie_app",
            password="dealgenie2025",
            port=5432
        )
        print(f"‚úÖ Connected to PostgreSQL: dealgenie_production")
        return conn
    except Exception as e:
        print(f"‚ùå Failed to connect to PostgreSQL: {e}")
        sys.exit(1)

def parse_numeric_value(value_str: str) -> Optional[float]:
    """Parse text values like '$537,555' or '4,648.0 (sq ft)' to numeric"""
    if not value_str or value_str.strip() == '':
        return None

    # Remove common text and formatting
    cleaned = value_str.replace('$', '').replace(',', '').replace('(sq ft)', '').replace('(ac)', '')
    cleaned = cleaned.replace('No data', '').strip()

    if not cleaned or cleaned.lower() in ['none', 'null', '']:
        return None

    try:
        return float(cleaned)
    except ValueError:
        return None

def parse_integer_value(value_str: str) -> Optional[int]:
    """Parse text values to integers"""
    if not value_str or value_str.strip() == '':
        return None

    cleaned = value_str.replace(',', '').strip()
    if not cleaned or cleaned.lower() in ['none', 'null', '']:
        return None

    try:
        return int(float(cleaned))  # Convert via float to handle decimals
    except ValueError:
        return None

def extract_and_transform_record(sqlite_record: Tuple) -> Dict[str, Any]:
    """Extract and transform a single SQLite record for PostgreSQL"""

    apn, pin, field_count, data_quality, extraction_method, \
    extracted_at, worker_id, coverage_percent, source_db, \
    merge_timestamp, json_str = sqlite_record

    # Parse JSON data
    property_data = {}
    try:
        json_data = json.loads(json_str)
        if 'property_data' in json_data:
            property_data = json_data['property_data']
    except json.JSONDecodeError:
        pass

    # Extract and transform key fields
    transformed_record = {
        # Primary identifiers
        'apn': apn,
        'pin_number': property_data.get('pin_number') or pin,
        'assessor_parcel_id': property_data.get('assessor_parcel_id'),

        # Site address and location
        'site_address': property_data.get('site_address') or property_data.get('divTab1_site_address'),
        'zip_code': property_data.get('zip_code') or property_data.get('divTab1_zip_code'),
        'council_district': property_data.get('council_district') or property_data.get('divTab2_council_district'),

        # Lot and parcel information
        'lot_parcel_area': property_data.get('lot_parcel_area') or property_data.get('divTab1_lotparcel_area'),
        'lotparcel_area_sqft': parse_numeric_value(property_data.get('lot_parcel_area') or property_data.get('divTab1_lotparcel_area')),
        'tract': property_data.get('divTab1_tract'),
        'lot': property_data.get('divTab1_lot'),
        'map_reference': property_data.get('divTab1_map_reference'),
        'map_sheet': property_data.get('divTab1_map_sheet'),
        'thomas_brothers_grid': property_data.get('divTab1_thomas_brothers_grid'),

        # Planning and zoning
        'community_plan_area': property_data.get('divTab2_community_plan_area'),
        'area_planning_commission': property_data.get('divTab2_area_planning_commission'),
        'neighborhood_council': property_data.get('divTab2_neighborhood_council'),
        'census_tract': property_data.get('divTab2_census_tract'),
        'ladbs_district_office': property_data.get('divTab2_ladbs_district_office'),
        'zoning_code': property_data.get('zoning_code') or property_data.get('divTab3_zoning'),
        'zoning_information': property_data.get('divTab3_zoning_information'),
        'general_plan_land_use': property_data.get('general_plan_land_use') or property_data.get('divTab3_general_plan_land_use'),
        'general_plan_note': property_data.get('divTab3_general_plan_note'),

        # Development incentives
        'ab_2334_low_vehicle_travel_area': property_data.get('divTab3_ab_2334_low_vehicle_travel_area'),
        'residential_market_area': property_data.get('divTab3_residential_market_area'),
        'nonresidential_market_area': property_data.get('divTab3_nonresidential_market_area'),
        'transit_oriented_communities': property_data.get('divTab3_transit_oriented_communities'),
        'transit_oriented_incentive_area': property_data.get('divTab3_transit_oriented_incentive_area'),
        'opportunity_corridors_incentive_area': property_data.get('divTab3_opportunity_corridors_incentive_area'),
        'corridor_transition_incentive_area': property_data.get('divTab3_corridor_transition_incentive_area'),
        'tcac_opportunity_area': property_data.get('divTab3_tcac_opportunity_area'),
        'ed_1_eligibility': property_data.get('divTab3_ed_1_eligibility'),

        # Assessment and valuation
        'apn_area': property_data.get('divTab4_apn_area'),
        'use_code': property_data.get('divTab4_use_code'),
        'assessed_land_val': property_data.get('divTab4_assessed_land_val'),
        'assessed_land_val_numeric': parse_numeric_value(property_data.get('divTab4_assessed_land_val')),
        'assessed_improvement_val': property_data.get('divTab4_assessed_improvement_val'),
        'assessed_improvement_val_numeric': parse_numeric_value(property_data.get('divTab4_assessed_improvement_val')),
        'last_owner_change': property_data.get('divTab4_last_owner_change'),
        'last_sale_amount': property_data.get('divTab4_last_sale_amount'),
        'last_sale_amount_numeric': parse_numeric_value(property_data.get('divTab4_last_sale_amount')),
        'tax_rate_area': property_data.get('divTab4_tax_rate_area'),
        'deed_ref_no': property_data.get('divTab4_deed_ref_no'),

        # Building characteristics
        'year_built': property_data.get('building_year_built') or property_data.get('divTab4_year_built'),
        'year_built_numeric': parse_integer_value(property_data.get('building_year_built') or property_data.get('divTab4_year_built')),
        'building_class': property_data.get('divTab4_building_class'),
        'number_of_units': property_data.get('divTab4_number_of_units'),
        'number_of_units_numeric': parse_integer_value(property_data.get('divTab4_number_of_units')),
        'number_of_bedrooms': property_data.get('divTab4_number_of_bedrooms'),
        'number_of_bedrooms_numeric': parse_integer_value(property_data.get('divTab4_number_of_bedrooms')),
        'number_of_bathrooms': property_data.get('divTab4_number_of_bathrooms'),
        'number_of_bathrooms_numeric': parse_integer_value(property_data.get('divTab4_number_of_bathrooms')),
        'building_square_footage': property_data.get('building_square_footage') or property_data.get('divTab4_building_square_footage'),
        'building_square_footage_numeric': parse_numeric_value(property_data.get('building_square_footage') or property_data.get('divTab4_building_square_footage')),
        'building_2': property_data.get('divTab4_building_2'),
        'building_3': property_data.get('divTab4_building_3'),
        'building_4': property_data.get('divTab4_building_4'),
        'building_5': property_data.get('divTab4_building_5'),

        # Housing regulations
        'rent_stabilization_ordinance': property_data.get('divTab4_rent_stabilization_ordinance') or property_data.get('divTab10_rent_stabilization_ordinance'),
        'just_cause_for_eviction_ordinance': property_data.get('divTab10_just_cause_for_eviction_ordinance'),
        'housing_crisis_act_replacement_review': property_data.get('divTab10_housing_crisis_act_replacement_review'),
        'housing_use_within_prior_5_years': property_data.get('divTab10_housing_use_within_prior_5_years'),

        # Planning commission
        'city_planning_commission': property_data.get('divTab5_city_planning_commission'),
        'ordinance': property_data.get('divTab5_ordinance'),
        'environmental': property_data.get('divTab5_environmental'),
        'board_file': property_data.get('divTab5_board_file'),

        # Environmental
        'farmland': property_data.get('divTab7_farmland'),
        'urban_agriculture_incentive_zone': property_data.get('divTab7_urban_agriculture_incentive_zone'),
        'flood_zone': property_data.get('divTab7_flood_zone'),
        'methane_hazard_site': property_data.get('divTab7_methane_hazard_site'),
        'special_grading_area': property_data.get('divTab7_special_grading_area'),

        # Seismic
        'nearest_fault': property_data.get('divTab8_nearest_fault'),
        'region': property_data.get('divTab8_region'),
        'fault_type': property_data.get('divTab8_fault_type'),
        'slip_rate': property_data.get('divTab8_slip_rate'),
        'slip_rate_numeric': parse_numeric_value(property_data.get('divTab8_slip_rate')),
        'slip_geometry': property_data.get('divTab8_slip_geometry'),
        'slip_type': property_data.get('divTab8_slip_type'),
        'down_dip_width': property_data.get('divTab8_down_dip_width'),
        'down_dip_width_numeric': parse_numeric_value(property_data.get('divTab8_down_dip_width')),
        'rupture_top': property_data.get('divTab8_rupture_top'),
        'rupture_top_numeric': parse_numeric_value(property_data.get('divTab8_rupture_top')),
        'rupture_bottom': property_data.get('divTab8_rupture_bottom'),
        'rupture_bottom_numeric': parse_numeric_value(property_data.get('divTab8_rupture_bottom')),
        'dip_angle': property_data.get('divTab8_dip_angle'),
        'dip_angle_numeric': parse_numeric_value(property_data.get('divTab8_dip_angle')),
        'maximum_magnitude': property_data.get('divTab8_maximum_magnitude'),
        'maximum_magnitude_numeric': parse_numeric_value(property_data.get('divTab8_maximum_magnitude')),

        # Housing department contact
        'direct_all_inquiries_to': property_data.get('divTab10_direct_all_inquiries_to'),
        'telephone': property_data.get('divTab10_telephone'),
        'website': property_data.get('divTab10_website'),
        'housing_notes': property_data.get('divTab10_notes'),

        # Public safety
        'bureau': property_data.get('divTab11_bureau'),
        'division_station': property_data.get('divTab11_division_station'),
        'reporting_district': property_data.get('divTab11_reporting_district'),
        'battallion': property_data.get('divTab11_battallion'),
        'district_fire_station': property_data.get('divTab11_district_fire_station'),

        # Data extraction metadata
        'field_count': field_count,
        'data_quality': data_quality,
        'extraction_method': extraction_method,
        'extracted_at': extracted_at,
        'worker_id': worker_id,
        'required_field_coverage_percent': coverage_percent,
        'source_database': source_db,
        'merge_timestamp': merge_timestamp
    }

    return transformed_record

def bulk_import_to_postgresql(sqlite_conn: sqlite3.Connection,
                             pg_conn: psycopg2.extensions.connection,
                             batch_size: int = 5000) -> bool:
    """Import data from SQLite to PostgreSQL in batches"""

    print(f"üöÄ Starting direct SQLite ‚Üí PostgreSQL import")
    print(f"üì¶ Batch size: {batch_size:,} records")

    sqlite_cursor = sqlite_conn.cursor()
    pg_cursor = pg_conn.cursor()

    try:
        # Get total count
        sqlite_cursor.execute("SELECT COUNT(*) FROM unified_property_data")
        total_records = sqlite_cursor.fetchone()[0]
        print(f"üìä Total records to import: {total_records:,}")

        # Prepare insert statement
        insert_sql = '''
            INSERT INTO unified_property_data (
                apn, pin_number, assessor_parcel_id, site_address, zip_code, council_district,
                lot_parcel_area, lotparcel_area_sqft, tract, lot, map_reference, map_sheet, thomas_brothers_grid,
                community_plan_area, area_planning_commission, neighborhood_council, census_tract, ladbs_district_office,
                zoning_code, zoning_information, general_plan_land_use, general_plan_note,
                ab_2334_low_vehicle_travel_area, residential_market_area, nonresidential_market_area,
                transit_oriented_communities, transit_oriented_incentive_area, opportunity_corridors_incentive_area,
                corridor_transition_incentive_area, tcac_opportunity_area, ed_1_eligibility,
                apn_area, use_code, assessed_land_val, assessed_land_val_numeric, assessed_improvement_val,
                assessed_improvement_val_numeric, last_owner_change, last_sale_amount, last_sale_amount_numeric,
                tax_rate_area, deed_ref_no, year_built, year_built_numeric, building_class,
                number_of_units, number_of_units_numeric, number_of_bedrooms, number_of_bedrooms_numeric,
                number_of_bathrooms, number_of_bathrooms_numeric, building_square_footage, building_square_footage_numeric,
                building_2, building_3, building_4, building_5, rent_stabilization_ordinance,
                just_cause_for_eviction_ordinance, housing_crisis_act_replacement_review, housing_use_within_prior_5_years,
                city_planning_commission, ordinance, environmental, board_file, farmland, urban_agriculture_incentive_zone,
                flood_zone, methane_hazard_site, special_grading_area, nearest_fault, region, fault_type,
                slip_rate, slip_rate_numeric, slip_geometry, slip_type, down_dip_width, down_dip_width_numeric,
                rupture_top, rupture_top_numeric, rupture_bottom, rupture_bottom_numeric, dip_angle, dip_angle_numeric,
                maximum_magnitude, maximum_magnitude_numeric, direct_all_inquiries_to, telephone, website, housing_notes,
                bureau, division_station, reporting_district, battallion, district_fire_station,
                field_count, data_quality, extraction_method, extracted_at, worker_id,
                required_field_coverage_percent, source_database, merge_timestamp
            ) VALUES (
                %(apn)s, %(pin_number)s, %(assessor_parcel_id)s, %(site_address)s, %(zip_code)s, %(council_district)s,
                %(lot_parcel_area)s, %(lotparcel_area_sqft)s, %(tract)s, %(lot)s, %(map_reference)s, %(map_sheet)s, %(thomas_brothers_grid)s,
                %(community_plan_area)s, %(area_planning_commission)s, %(neighborhood_council)s, %(census_tract)s, %(ladbs_district_office)s,
                %(zoning_code)s, %(zoning_information)s, %(general_plan_land_use)s, %(general_plan_note)s,
                %(ab_2334_low_vehicle_travel_area)s, %(residential_market_area)s, %(nonresidential_market_area)s,
                %(transit_oriented_communities)s, %(transit_oriented_incentive_area)s, %(opportunity_corridors_incentive_area)s,
                %(corridor_transition_incentive_area)s, %(tcac_opportunity_area)s, %(ed_1_eligibility)s,
                %(apn_area)s, %(use_code)s, %(assessed_land_val)s, %(assessed_land_val_numeric)s, %(assessed_improvement_val)s,
                %(assessed_improvement_val_numeric)s, %(last_owner_change)s, %(last_sale_amount)s, %(last_sale_amount_numeric)s,
                %(tax_rate_area)s, %(deed_ref_no)s, %(year_built)s, %(year_built_numeric)s, %(building_class)s,
                %(number_of_units)s, %(number_of_units_numeric)s, %(number_of_bedrooms)s, %(number_of_bedrooms_numeric)s,
                %(number_of_bathrooms)s, %(number_of_bathrooms_numeric)s, %(building_square_footage)s, %(building_square_footage_numeric)s,
                %(building_2)s, %(building_3)s, %(building_4)s, %(building_5)s, %(rent_stabilization_ordinance)s,
                %(just_cause_for_eviction_ordinance)s, %(housing_crisis_act_replacement_review)s, %(housing_use_within_prior_5_years)s,
                %(city_planning_commission)s, %(ordinance)s, %(environmental)s, %(board_file)s, %(farmland)s, %(urban_agriculture_incentive_zone)s,
                %(flood_zone)s, %(methane_hazard_site)s, %(special_grading_area)s, %(nearest_fault)s, %(region)s, %(fault_type)s,
                %(slip_rate)s, %(slip_rate_numeric)s, %(slip_geometry)s, %(slip_type)s, %(down_dip_width)s, %(down_dip_width_numeric)s,
                %(rupture_top)s, %(rupture_top_numeric)s, %(rupture_bottom)s, %(rupture_bottom_numeric)s, %(dip_angle)s, %(dip_angle_numeric)s,
                %(maximum_magnitude)s, %(maximum_magnitude_numeric)s, %(direct_all_inquiries_to)s, %(telephone)s, %(website)s, %(housing_notes)s,
                %(bureau)s, %(division_station)s, %(reporting_district)s, %(battallion)s, %(district_fire_station)s,
                %(field_count)s, %(data_quality)s, %(extraction_method)s, %(extracted_at)s, %(worker_id)s,
                %(required_field_coverage_percent)s, %(source_database)s, %(merge_timestamp)s
            )
        '''

        # Clear existing data
        print("üóëÔ∏è  Clearing existing data...")
        pg_cursor.execute("DELETE FROM unified_property_data")
        pg_conn.commit()

        # Process in batches
        imported_count = 0
        batch_num = 0

        # Get all records
        sqlite_cursor.execute('''
            SELECT apn, pin, field_count, data_quality, extraction_method,
                   extracted_at, worker_id, required_field_coverage_percent,
                   source_database, merge_timestamp, extracted_fields_json
            FROM unified_property_data
            ORDER BY apn
        ''')

        batch_data = []

        while True:
            batch_num += 1
            print(f"üì¶ Processing batch {batch_num}...")

            # Fetch batch
            batch_records = sqlite_cursor.fetchmany(batch_size)
            if not batch_records:
                # Process final batch if any data remains
                if batch_data:
                    pg_cursor.executemany(insert_sql, batch_data)
                    pg_conn.commit()
                    imported_count += len(batch_data)
                    print(f"‚úÖ Final batch imported: {len(batch_data):,} records")
                break

            # Transform batch
            batch_data = []
            for record in batch_records:
                try:
                    transformed = extract_and_transform_record(record)
                    batch_data.append(transformed)
                except Exception as e:
                    print(f"‚ö†Ô∏è  Error transforming record {record[0]}: {e}")
                    continue

            # Insert batch
            if batch_data:
                pg_cursor.executemany(insert_sql, batch_data)
                pg_conn.commit()

                imported_count += len(batch_data)
                print(f"‚úÖ Batch {batch_num} imported: {len(batch_data):,} records "
                      f"(Total: {imported_count:,}/{total_records:,})")

        print(f"üéâ Import completed successfully!")
        print(f"üìä Total records imported: {imported_count:,}")

        return True

    except Exception as e:
        print(f"‚ùå Import failed: {e}")
        pg_conn.rollback()
        return False

def verify_postgresql_import(pg_conn: psycopg2.extensions.connection) -> bool:
    """Verify the PostgreSQL import"""

    print(f"üîç Verifying PostgreSQL import...")

    try:
        cursor = pg_conn.cursor()

        # Count records
        cursor.execute("SELECT COUNT(*) FROM unified_property_data")
        count = cursor.fetchone()[0]
        print(f"‚úÖ Total records in PostgreSQL: {count:,}")

        # Check sample data
        cursor.execute('''
            SELECT apn, site_address, zoning_code, assessed_land_val_numeric,
                   ST_AsText(geom), property_age, total_assessed_value
            FROM unified_property_data
            WHERE geom IS NOT NULL
            LIMIT 3
        ''')

        sample_records = cursor.fetchall()
        print(f"‚úÖ Sample records with PostGIS geometry:")
        for record in sample_records:
            apn, address, zoning, land_val, geom_text, age, total_val = record
            print(f"   APN: {apn}, Address: {address[:30]}...")
            print(f"   Geometry: {geom_text[:40]}...")
            print(f"   Age: {age}, Total Value: ${total_val:,.0f}" if total_val else "")

        cursor.close()
        return True

    except Exception as e:
        print(f"‚ùå Verification failed: {e}")
        return False

def main():
    """Main execution function"""

    print("üóÉÔ∏è  DIRECT ZIMAS SQLITE ‚Üí POSTGRESQL IMPORT")
    print("=" * 70)

    start_time = time.time()

    # Connect to databases
    sqlite_conn = connect_to_sqlite()
    pg_conn = connect_to_postgresql()

    try:
        # Import data
        success = bulk_import_to_postgresql(sqlite_conn, pg_conn)

        if success:
            # Verify import
            verify_postgresql_import(pg_conn)

            elapsed_time = time.time() - start_time
            print(f"\n‚è±Ô∏è  Total import time: {elapsed_time:.1f} seconds")
            print(f"üöÄ Import rate: {457768 / elapsed_time:.0f} records/second")

            print(f"\n‚úÖ DIRECT IMPORT COMPLETE!")
            print(f"üóÉÔ∏è  457,768 ZIMAS properties imported to PostgreSQL")
            print(f"üåç PostGIS geometry and computed fields populated")
            print(f"üìä All 97 ZIMAS fields available for analysis")

        else:
            print(f"‚ùå Import failed")

    finally:
        sqlite_conn.close()
        pg_conn.close()

if __name__ == "__main__":
    main()